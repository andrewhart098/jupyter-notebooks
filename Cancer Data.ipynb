{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>683.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "      <td>699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1071704.098712</td>\n",
       "      <td>4.417740</td>\n",
       "      <td>3.134478</td>\n",
       "      <td>3.207439</td>\n",
       "      <td>2.806867</td>\n",
       "      <td>3.216023</td>\n",
       "      <td>3.544656</td>\n",
       "      <td>3.437768</td>\n",
       "      <td>2.866953</td>\n",
       "      <td>1.589413</td>\n",
       "      <td>0.344778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>617095.729819</td>\n",
       "      <td>2.815741</td>\n",
       "      <td>3.051459</td>\n",
       "      <td>2.971913</td>\n",
       "      <td>2.855379</td>\n",
       "      <td>2.214300</td>\n",
       "      <td>3.643857</td>\n",
       "      <td>2.438364</td>\n",
       "      <td>3.053634</td>\n",
       "      <td>1.715078</td>\n",
       "      <td>0.475636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>61634.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>870688.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1171710.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1238298.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>13454352.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    ID  Clump Thickness  Uniformity of Cell Size  \\\n",
       "count       699.000000       699.000000               699.000000   \n",
       "mean    1071704.098712         4.417740                 3.134478   \n",
       "std      617095.729819         2.815741                 3.051459   \n",
       "min       61634.000000         1.000000                 1.000000   \n",
       "25%      870688.500000         2.000000                 1.000000   \n",
       "50%     1171710.000000         4.000000                 1.000000   \n",
       "75%     1238298.000000         6.000000                 5.000000   \n",
       "max    13454352.000000        10.000000                10.000000   \n",
       "\n",
       "       Uniformity of Cell Shape  Marginal Adhesion  \\\n",
       "count                699.000000         699.000000   \n",
       "mean                   3.207439           2.806867   \n",
       "std                    2.971913           2.855379   \n",
       "min                    1.000000           1.000000   \n",
       "25%                    1.000000           1.000000   \n",
       "50%                    1.000000           1.000000   \n",
       "75%                    5.000000           4.000000   \n",
       "max                   10.000000          10.000000   \n",
       "\n",
       "       Single Epithelial Cell Size  Bare Nuclei  Bland Chromatin  \\\n",
       "count                   699.000000   683.000000       699.000000   \n",
       "mean                      3.216023     3.544656         3.437768   \n",
       "std                       2.214300     3.643857         2.438364   \n",
       "min                       1.000000     1.000000         1.000000   \n",
       "25%                       2.000000     1.000000         2.000000   \n",
       "50%                       2.000000     1.000000         3.000000   \n",
       "75%                       4.000000     6.000000         5.000000   \n",
       "max                      10.000000    10.000000        10.000000   \n",
       "\n",
       "       Normal Nucleoli     Mitoses       Class  \n",
       "count       699.000000  699.000000  699.000000  \n",
       "mean          2.866953    1.589413    0.344778  \n",
       "std           3.053634    1.715078    0.475636  \n",
       "min           1.000000    1.000000    0.000000  \n",
       "25%           1.000000    1.000000    0.000000  \n",
       "50%           1.000000    1.000000    0.000000  \n",
       "75%           4.000000    1.000000    1.000000  \n",
       "max          10.000000   10.000000    1.000000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this notebook I am going to use the following data\n",
    "# http://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\n",
    "\n",
    "# The name of this data set is: Breast Cancer Wisconsin (Diagnostic) Data Set\n",
    "# The columns are the following\n",
    "\n",
    "#    #  Attribute                     Domain\n",
    "#    -- -----------------------------------------\n",
    "#    1. Sample code number            id number\n",
    "#    2. Clump Thickness               1 - 10\n",
    "#    3. Uniformity of Cell Size       1 - 10\n",
    "#    4. Uniformity of Cell Shape      1 - 10\n",
    "#    5. Marginal Adhesion             1 - 10\n",
    "#    6. Single Epithelial Cell Size   1 - 10\n",
    "#    7. Bare Nuclei                   1 - 10\n",
    "#    8. Bland Chromatin               1 - 10\n",
    "#    9. Normal Nucleoli               1 - 10\n",
    "#   10. Mitoses                       1 - 10\n",
    "#   11. Class:                        (2 for benign, 4 for malignant)\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# df = pd.read_csv('../data/wdbc.csv', names=['ID', 'Diagnosis', 'radius', 'texture', 'perimeter', 'area', 'smoothness', \n",
    "#                                            'compactness', 'concavity', 'concave_points', 'symmetry', 'fractal_dimension'],\n",
    "#                header=None);\n",
    "header_names = ['ID', 'Clump Thickness', 'Uniformity of Cell Size', 'Uniformity of Cell Shape', 'Marginal Adhesion', \n",
    "                'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin', 'Normal Nucleoli', 'Mitoses', 'Class']\n",
    "df = pd.read_csv('../data/wdbc.csv', header=None, names=header_names, na_values=[\"?\"])\n",
    "df['Class'] = df['Class'].replace(2, 0)\n",
    "df['Class'] = df['Class'].replace(4, 1)\n",
    "def pr(T):\n",
    "    any(x.name == \"?\" for x in T)\n",
    "# Left off here - some rows have a '?' which can't be trained by sklearn - remove rows with these question marks\n",
    "# df[(df['Clump Thickness'] != '?') & (df['Uniformity of Cell Size'] != '?') & (df['Uniformity of Cell Shape'] != '?') &\n",
    "#    (df['Marginal Adhesion'] != '?') & (df['Single Epithelial Cell Size'] != '?') & (df['Bare Nuclei'] != '?') & \n",
    "#    (df['Bland Chromatin'] != '?') & (df['Normal Nucleoli'] != '?') & (df['Mitoses'] != '?') & \n",
    "#    (df['Class'] != '?')]\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 10.,   8.,   4., ...,   3.,  10.,   4.],\n",
       "       [  3.,   1.,   4., ...,   1.,   1.,   1.],\n",
       "       [  2.,   1.,   1., ...,   3.,   1.,   1.],\n",
       "       ..., \n",
       "       [  9.,  10.,  10., ...,  10.,  10.,  10.],\n",
       "       [  5.,   8.,   7., ...,   5.,   7.,   1.],\n",
       "       [  3.,   1.,   1., ...,   1.,   1.,   1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing \n",
    "from sklearn import cross_validation\n",
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "# 1 - shuffle and then split data into training and testing data\n",
    "shuffled = df.iloc[np.random.permutation(len(df))]\n",
    "\n",
    "# 2 - using Imputer, replace NaN with average for the column\n",
    "imp = Imputer(missing_values='NaN', strategy='median', axis=1)\n",
    "fit_data = imp.fit(shuffled)\n",
    "clean_data = imp.transform(shuffled)\n",
    "clean_df = pd.DataFrame(clean_data, columns=header_names)\n",
    "\n",
    "features = clean_df.drop(['Class', 'ID'], 1)\n",
    "labels = clean_df['Class']\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(features, labels, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94285714285714284"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use support vector machine to classify data\n",
    "from sklearn import svm\n",
    "\n",
    "clf1 = svm.SVC()\n",
    "clf1.fit(X_train, y_train)\n",
    "clf1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86959137564921929"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ordinary least squares: http://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf2 = linear_model.LinearRegression()\n",
    "clf2.fit(X_train, y_train)\n",
    "clf2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695655381723647"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bayesian Ridge Regression: http://scikit-learn.org/stable/modules/linear_model.html#bayesian-regression\n",
    "\n",
    "clf3 = linear_model.BayesianRidge()\n",
    "clf3.fit(X_train, y_train)\n",
    "clf3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86717601125567323"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Automatic relevance determination: http://scikit-learn.org/stable/modules/linear_model.html#automatic-relevance-determination-ard\n",
    "# http://papers.nips.cc/paper/3372-a-new-view-of-automatic-relevance-determination\n",
    "\n",
    "clf4 = linear_model.ARDRegression()\n",
    "clf4.fit(X_train, y_train)\n",
    "clf4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97374701670644392"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# logisitic regression: http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "\n",
    "clf4 = linear_model.LogisticRegression()\n",
    "clf4.fit(X_train, y_train)\n",
    "clf4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85202863961813846"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stochastic Gradient Descent: http://scikit-learn.org/stable/modules/linear_model.html#stochastic-gradient-descent-sgd\n",
    "\n",
    "clf5 = linear_model.SGDClassifier()\n",
    "clf5.fit(X_train, y_train)\n",
    "clf5.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9880668257756563"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nearest Neighbor Classifiers: \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier\n",
    "from sklearn import neighbors\n",
    "\n",
    "clf6 = neighbors.KNeighborsClassifier()\n",
    "clf6.fit(X_train, y_train)\n",
    "clf6.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
